import { CaseStudyContent } from '../types'

export const docusearchCaseStudy: CaseStudyContent = {
  id: 'docusearch',
  title: 'DocuSearch',
  tagline: 'Designing Transparency into RAG Systems',

  problem: {
    title: 'Black Box Document Systems',
    content: [
      'I built DocuSearch to solve a problem I kept running into: most RAG systems let you upload documents, but once they\'re in, they become invisible. You can\'t review them for outdated information, you can\'t see what the AI is actually working with, and you can\'t manage them like regular files.',
      'Traditional RAG systems treat documents like database entries—once uploaded, they disappear into embeddings and vector stores. This creates real problems:',
      'No visibility - You can\'t see what documents are actually in the system',
      'No verification - Can\'t check if information is current or correct',
      'No natural interaction - People need visual browsing, AI needs semantic search',
      'Limited formats - Most systems handle PDFs but struggle with audio, presentations, or mixed media',
      'I realized this was fundamentally a dual-interface design problem. People and AI agents need different ways to interact with the same information, but most systems only optimize for one.',
    ],
  },

  understanding: {
    title: 'Understanding the Users (Both People and AI)',
    content: [
      'My research process involved both traditional UX methods and something newer—what I call Agent Experience (AGx) research. I asked AI agents what context formats they preferred and how they wanted to consume document information.',
      'What I learned from people:',
      '• Need to see thumbnails and previews before diving into documents',
      '• Want to verify sources when AI gives answers',
      '• Prefer browsing over searching when exploring content',
      '• Need confidence that information is current',
      '',
      'What I learned from AI agents:',
      '• Prefer hierarchical semantic search over keyword matching',
      '• Work best with multi-modal understanding (both text and visual context)',
      '• Need structured metadata but benefit from unstructured context',
      '• Prefer filesystem operations over database queries',
    ],
    keyInsights: [
      'Both people and AI agents need transparency, just in different forms',
      'File-native architecture serves both audiences better than database abstraction',
      'Multi-modal search (understanding both images and text) dramatically improves retrieval quality',
    ],
  },

  solution: {
    title: 'File-Native Semantic Search',
    content: [
      'I designed DocuSearch around three core principles:',
      '',
      '1. Dual Interface for Dual Users',
      'People interact through visual browsing: Card-based library with thumbnails, audio player with waveform visualization, image carousel for presentations, and full-text transcripts for audio files.',
      '',
      'AI agents interact through semantic search: ColPali v1.2 multi-modal retrieval (understands both images and text), ChromaDB vector store for similarity search, REST API for programmatic access, and structured metadata for precise filtering.',
      '',
      '2. File-Native Architecture',
      'Instead of hiding documents in a database, I built everything on the filesystem. Documents live in a real directory structure, AI agents can use standard file operations, people can access files directly if needed, and the system orchestrates between file storage and vector embeddings.',
      '',
      'This emerged from understanding how AI agents actually prefer to work—they\'re more comfortable with file operations than database queries.',
      '',
      '3. Maximum Format Support',
      'Using Docling as a unified parser, the system handles 21 document formats: PDF, DOCX, PPTX, XLSX (with visual processing), MP3, WAV (with ID3 metadata and Whisper transcription), HTML, Markdown, plain text, and Images (JPEG, PNG, TIFF).',
    ],
    features: [
      'Real-time processing with stage-by-stage progress feedback',
      'Kraft paper theme system with five color schemes (Sand, Clay, Slate, Moss, Ocean)',
      'Research interface with source citations and confidence indicators',
      'Audio transcription with VTT captions and full-text search',
      'WebSocket real-time updates (no polling needed)',
      'Comprehensive error handling with 98% test coverage',
    ],
  },

  impact: {
    title: 'Transparency Changes Everything',
    content: [
      'What changed for users:',
      '• "I can finally see what documents I\'ve added" - Visual library made the invisible visible',
      '• "I trust the answers more because I can check sources" - Citations enable verification',
      '• "It handles my meeting recordings now" - Audio transcription opened new use cases',
      '• "Feels like browsing my files, not using a database" - Natural filesystem interaction',
      '',
      'What changed for AI agents:',
      '• Multi-modal search understands document structure, not just text',
      '• Semantic retrieval finds relevant content even without keyword matches',
      '• File-based architecture allows standard agent workflows',
      '• Structured metadata enables precise filtering when needed',
      '',
      'This project reinforced that AI UX isn\'t just traditional UX with a chatbot—it\'s designing systems where people and AI agents collaborate naturally.',
      '',
      'Key principles I validated:',
      '1. Transparency serves everyone - People need visual feedback, AI needs structured data, but both benefit from seeing what\'s happening',
      '2. File-native beats database-native - Agents prefer filesystem operations, people want direct access',
      '3. Multi-modal search changes everything - When AI understands document structure (not just text), retrieval quality dramatically improves',
      '4. Real-time feedback is crucial - Both people and agents need to know when documents are ready for use',
    ],
    metrics: [
      'Built in 15 consecutive days (October 6-20, 2025) with 207 commits',
      'Processes 21 document formats with unified pipeline',
      'Sub-second semantic search across 100+ documents',
      'Real-time updates via WebSocket',
      '98% test coverage with comprehensive error handling',
      '~15,000 lines of code (backend + frontend)',
    ],
  },

  metadata: {
    role: 'Solo Designer & Developer',
    type: 'Open-source Project',
    stack: [
      'React 19',
      'TypeScript',
      'Python 3.14',
      'FastAPI',
      'ColPali v1.2',
      'ChromaDB',
      'Whisper ASR',
      'Docling 2.57.0',
      'Zustand',
      'React Query 5',
    ],
    skills: [
      'Dual-interface design (people + AI agent UX)',
      'Agent Experience (AGx) research and design',
      'Multi-modal system architecture',
      'Semantic search + traditional UX patterns',
      'File-native system design',
      'Real-time processing with feedback loops',
      'Full-stack development',
    ],
    year: '2025',
    githubUrl: 'https://github.com/tuckertucker/tkr-docusearch',
  },
}
